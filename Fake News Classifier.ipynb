{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake News Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the exercises in the https://www.datacamp.com/courses/natural-language-processing-fundamentals-in-python course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the csv file of labeled news stories into a dataframe\n",
    "df1 = pd.read_csv('firsthalf.csv')\n",
    "df2 = pd.read_csv('secondhalf.csv')\n",
    "df = df1.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the head of df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6336, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the number of rows and columns in the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series to store the labels: y\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"],y,\n",
    "                                    test_size=0.33,random_state=53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method puts together a list of all the words in the train data. This list is called a vocabulary. Each row in the train data is called a document. This method next creates a dataframe that has the same number of rows as the train data, but each word will get its own column. At the intersection of each column and row in the dataframe is a count of the number of times the word for that column occured in the document for that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a CountVectorizer object: count_vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training data using only the 'text' column values: count_train \n",
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data using only the 'text' column values: count_test \n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '000035', '00006', '0001', '0001pt', '000ft', '000km', '001']\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 features of the count_vectorizer\n",
    "print(count_vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57219 features in the count vectorizer object for the train data\n"
     ]
    }
   ],
   "source": [
    "feat = count_vectorizer.get_feature_names()\n",
    "print(\"There are\",len(feat),\"features in the count vectorizer object for the train data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CountVectorizer DataFrame: count_df\n",
    "count_df = pd.DataFrame(count_train.A,\n",
    "                        columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>000035</th>\n",
       "      <th>00006</th>\n",
       "      <th>0001</th>\n",
       "      <th>0001pt</th>\n",
       "      <th>000ft</th>\n",
       "      <th>000km</th>\n",
       "      <th>001</th>\n",
       "      <th>...</th>\n",
       "      <th>حلب</th>\n",
       "      <th>عربي</th>\n",
       "      <th>عن</th>\n",
       "      <th>لم</th>\n",
       "      <th>ما</th>\n",
       "      <th>محاولات</th>\n",
       "      <th>من</th>\n",
       "      <th>هذا</th>\n",
       "      <th>والمرضى</th>\n",
       "      <th>ยงade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3883</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  0000  000035  00006  0001  0001pt  000ft  000km  001  ...    \\\n",
       "410    0    1     0       0      0     0       0      0      0    0  ...     \n",
       "3883   0    1     0       0      0     0       0      0      0    0  ...     \n",
       "909    0    0     0       0      0     0       0      0      0    0  ...     \n",
       "1475   0    1     0       0      0     0       0      0      0    0  ...     \n",
       "2586   0    0     0       0      0     0       0      0      0    0  ...     \n",
       "4081   0    0     0       0      0     0       0      0      0    0  ...     \n",
       "2002   0    0     0       0      0     0       0      0      0    0  ...     \n",
       "1070   0    0     0       0      0     0       0      0      0    0  ...     \n",
       "\n",
       "      حلب  عربي  عن  لم  ما  محاولات  من  هذا  والمرضى  ยงade  \n",
       "410     0     0   0   0   0        0   0    0        0      0  \n",
       "3883    0     0   0   0   0        0   0    0        0      0  \n",
       "909     0     0   0   0   0        0   0    0        0      0  \n",
       "1475    0     0   0   0   0        0   0    0        0      0  \n",
       "2586    0     0   0   0   0        0   0    0        0      0  \n",
       "4081    0     0   0   0   0        0   0    0        0      0  \n",
       "2002    0     0   0   0   0        0   0    0        0      0  \n",
       "1070    0     0   0   0   0        0   0    0        0      0  \n",
       "\n",
       "[8 rows x 57219 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a sample of the rows in count_df\n",
    "count_df.sample(frac=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a similar method. It combines CountVectorizer with a tdidf transformation. The tf stands for term frequency, which counts the number of times that each word occurs in each row. The idf is an abbreviation for inverse document frequency, which means it gives less weight to common terms and more weight to rare terms. The column for each word becomes a vector in a matrix, with the documents forming its rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\",max_df=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training data: tfidf_train \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data: tfidf_test \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '000035', '00006', '0001', '0001pt', '000ft', '000km', '001']\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 features\n",
    "print(tfidf_vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57219 features in the tfidf vectorizer object for the train data\n"
     ]
    }
   ],
   "source": [
    "tfidffeat = tfidf_vectorizer.get_feature_names()\n",
    "print(\"There are\",len(tfidffeat),\"features in the tfidf vectorizer object for the train data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.06164315 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train.A[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A,\n",
    "                        columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>000035</th>\n",
       "      <th>00006</th>\n",
       "      <th>0001</th>\n",
       "      <th>0001pt</th>\n",
       "      <th>000ft</th>\n",
       "      <th>000km</th>\n",
       "      <th>001</th>\n",
       "      <th>...</th>\n",
       "      <th>حلب</th>\n",
       "      <th>عربي</th>\n",
       "      <th>عن</th>\n",
       "      <th>لم</th>\n",
       "      <th>ما</th>\n",
       "      <th>محاولات</th>\n",
       "      <th>من</th>\n",
       "      <th>هذا</th>\n",
       "      <th>والمرضى</th>\n",
       "      <th>ยงade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3679</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  0000  000035  00006  0001  0001pt  000ft  000km  001  ...    \\\n",
       "3679  0.0  0.0   0.0     0.0    0.0   0.0     0.0    0.0    0.0  0.0  ...     \n",
       "299   0.0  0.0   0.0     0.0    0.0   0.0     0.0    0.0    0.0  0.0  ...     \n",
       "3588  0.0  0.0   0.0     0.0    0.0   0.0     0.0    0.0    0.0  0.0  ...     \n",
       "4113  0.0  0.0   0.0     0.0    0.0   0.0     0.0    0.0    0.0  0.0  ...     \n",
       "3840  0.0  0.0   0.0     0.0    0.0   0.0     0.0    0.0    0.0  0.0  ...     \n",
       "2069  0.0  0.0   0.0     0.0    0.0   0.0     0.0    0.0    0.0  0.0  ...     \n",
       "1059  0.0  0.0   0.0     0.0    0.0   0.0     0.0    0.0    0.0  0.0  ...     \n",
       "2121  0.0  0.0   0.0     0.0    0.0   0.0     0.0    0.0    0.0  0.0  ...     \n",
       "\n",
       "      حلب  عربي   عن   لم   ما  محاولات   من  هذا  والمرضى  ยงade  \n",
       "3679  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "299   0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "3588  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "4113  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "3840  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "2069  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "1059  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "2121  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "\n",
       "[8 rows x 57219 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a sample of the rows in tfidf_df\n",
    "tfidf_df.sample(frac=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "This means the two matrices have the same columns\n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference in columns: difference\n",
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "print(difference)\n",
    "print('This means the two matrices have the same columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "This means the two matrices have the same rows and columns, but different values in their cells\n"
     ]
    }
   ],
   "source": [
    "# Check whether the DataFrames are equal\n",
    "print(count_df.equals(tfidf_df))\n",
    "print('This means the two matrices have the same rows and columns, but different values in their cells')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier for CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Naive Bayes, the rows become classes and the word vector columns become features. The algorithm assumes, naively, that the probability of each feature happening is independent of all other features. However, it uses the Bayes formula from statistics to calculate, quite reliably, the probability that a class belong to a target label (fake or real news), based on a series of probabilities that are already known about the features and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.8957436633189861\n",
      "\n",
      "confusion matrix:\n",
      "[[ 873  138]\n",
      " [  80 1000]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.92      0.86      0.89      1011\n",
      "        REAL       0.88      0.93      0.90      1080\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2091\n",
      "   macro avg       0.90      0.89      0.90      2091\n",
      "weighted avg       0.90      0.90      0.90      2091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy score\n",
    "print (\"accuracy score:\",metrics.accuracy_score(y_test, pred))\n",
    "print()\n",
    "# Calculate the confusion matrix and report\n",
    "print (\"confusion matrix:\")\n",
    "print (metrics.confusion_matrix(y_test, pred, labels=['FAKE', 'REAL']))\n",
    "print()\n",
    "print (\"classification report:\")\n",
    "print (metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier for TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier uses a multinomial distribution, which calculates the probability of success given a certain number of categories and trials. The tfidf vector values give the classifier's naive bayes formula a better start at predicting which target label each row class belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.8531802965088474\n",
      "\n",
      "confusion matrix:\n",
      "[[ 737  274]\n",
      " [  33 1047]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.96      0.73      0.83      1011\n",
      "        REAL       0.79      0.97      0.87      1080\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      2091\n",
      "   macro avg       0.87      0.85      0.85      2091\n",
      "weighted avg       0.87      0.85      0.85      2091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy score\n",
    "print (\"accuracy score:\",metrics.accuracy_score(y_test, pred))\n",
    "print()\n",
    "# Calculate the confusion matrix and report\n",
    "print (\"confusion matrix:\")\n",
    "print (metrics.confusion_matrix(y_test, pred, labels=['FAKE', 'REAL']))\n",
    "print()\n",
    "print (\"classification report:\")\n",
    "print (metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will search for an ideal value for the alpha parameter, which will maximize the accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(0,1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to store the alphas and scores\n",
    "alphscordct = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.0\n",
      "Score:  0.8919177427068389\n",
      "\n",
      "Alpha:  0.1\n",
      "Score:  0.9014825442372071\n",
      "\n",
      "Alpha:  0.2\n",
      "Score:  0.8952654232424677\n",
      "\n",
      "Alpha:  0.30000000000000004\n",
      "Score:  0.8923959827833573\n",
      "\n",
      "Alpha:  0.4\n",
      "Score:  0.8857006217120995\n",
      "\n",
      "Alpha:  0.5\n",
      "Score:  0.8809182209469153\n",
      "\n",
      "Alpha:  0.6000000000000001\n",
      "Score:  0.8761358201817312\n",
      "\n",
      "Alpha:  0.7000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sterling\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8699186991869918\n",
      "\n",
      "Alpha:  0.8\n",
      "Score:  0.8656145384983261\n",
      "\n",
      "Alpha:  0.9\n",
      "Score:  0.8574844571975132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    score=train_and_predict(alpha)\n",
    "    alphscordct[alpha]=score\n",
    "    print('Score: ', score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 is the best alpha value for this model\n"
     ]
    }
   ],
   "source": [
    "# get the best alpha and score\n",
    "alphscor = sorted(alphscordct, key=alphscordct.get, reverse=True)\n",
    "bestalpha = alphscor[0]\n",
    "print(bestalpha, \"is the best alpha value for this model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB(alpha=bestalpha)\n",
    "# Fit to the training data\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "# Predict the labels: pred\n",
    "pred = nb_classifier.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.9014825442372071\n",
      "\n",
      "confusion matrix:\n",
      "[[ 873  138]\n",
      " [  68 1012]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.93      0.86      0.89      1011\n",
      "        REAL       0.88      0.94      0.91      1080\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2091\n",
      "   macro avg       0.90      0.90      0.90      2091\n",
      "weighted avg       0.90      0.90      0.90      2091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy score\n",
    "print (\"accuracy score:\",metrics.accuracy_score(y_test, pred))\n",
    "print()\n",
    "# Calculate the confusion matrix and report\n",
    "print (\"confusion matrix:\")\n",
    "print (metrics.confusion_matrix(y_test, pred, labels=['FAKE', 'REAL']))\n",
    "print()\n",
    "print (\"classification report:\")\n",
    "print (metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the features used by the model, and the weights attached to those features, when predicting whether a news article is fake or real. The top 20 lists of features for both types of articles appear below. The fake features are mostly numbers and timestamps, while the real ones are primarily names of politicians or terms used in news reports about politics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class labels: class_labels\n",
    "class_labels = nb_classifier.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the features: feature_names\n",
    "feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\n",
    "feat_with_weights = sorted(zip(nb_classifier.coef_[0], feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAKE [(-12.645624315988039, '0000'), (-12.645624315988039, '000035'), (-12.645624315988039, '0001'), (-12.645624315988039, '0001pt'), (-12.645624315988039, '000km'), (-12.645624315988039, '0011'), (-12.645624315988039, '004s'), (-12.645624315988039, '005'), (-12.645624315988039, '006s'), (-12.645624315988039, '007'), (-12.645624315988039, '007s'), (-12.645624315988039, '008s'), (-12.645624315988039, '009'), (-12.645624315988039, '0099'), (-12.645624315988039, '00am'), (-12.645624315988039, '00p'), (-12.645624315988039, '00pm'), (-12.645624315988039, '014'), (-12.645624315988039, '015'), (-12.645624315988039, '01am')]\n"
     ]
    }
   ],
   "source": [
    "# Print the first class label and the top 20 feat_with_weights entries\n",
    "print(class_labels[0][:20], feat_with_weights[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL [(-6.796871752001991, 'states'), (-6.744968914278907, 'rubio'), (-6.715233928796038, 'voters'), (-6.7113804591184945, 'house'), (-6.688499966355614, 'republicans'), (-6.6536495791034005, 'bush'), (-6.627623046863042, 'percent'), (-6.575508687311647, 'people'), (-6.565574971494339, 'new'), (-6.539521007839014, 'party'), (-6.464376056331245, 'state'), (-6.449112623035523, 'cruz'), (-6.4172252465408235, 'republican'), (-6.368564224937915, 'campaign'), (-6.3586088687509985, 'sanders'), (-6.340418204788652, 'president'), (-6.154020115959707, 'obama'), (-5.768689598834805, 'clinton'), (-5.624503296971422, 'said'), (-5.349386275175854, 'trump')]\n"
     ]
    }
   ],
   "source": [
    "# Print the second class label and the bottom 20 feat_with_weights entries\n",
    "print(class_labels[1][-20:], feat_with_weights[-20:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
